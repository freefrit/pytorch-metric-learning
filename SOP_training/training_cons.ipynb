{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oLJsLLdC-X2c"
   },
   "source": [
    "## Import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5NckoTIW-isk"
   },
   "outputs": [],
   "source": [
    "# Packages for pytorch metric learning\n",
    "%matplotlib inline\n",
    "from pytorch_metric_learning import losses, miners, samplers, trainers, testers\n",
    "from pytorch_metric_learning.utils import common_functions\n",
    "import pytorch_metric_learning.utils.logging_presets as logging_presets\n",
    "from pytorch_metric_learning.utils.accuracy_calculator import AccuracyCalculator\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import umap\n",
    "from cycler import cycler\n",
    "import record_keeper\n",
    "import pytorch_metric_learning\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "logging.info(\"VERSION %s\"%pytorch_metric_learning.__version__)\n",
    "\n",
    "# Packages for preparing dataset\n",
    "import json\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sy1eUrkEAC2z"
   },
   "source": [
    "## Simple model def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Eb4VwGm3AF41"
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    # layer_sizes[0] is the dimension of the input\n",
    "    # layer_sizes[-1] is the dimension of the output\n",
    "    def __init__(self, layer_sizes, final_relu=False):\n",
    "        super().__init__()\n",
    "        layer_list = []\n",
    "        layer_sizes = [int(x) for x in layer_sizes]\n",
    "        num_layers = len(layer_sizes) - 1\n",
    "        final_relu_layer = num_layers if final_relu else num_layers - 1\n",
    "        for i in range(len(layer_sizes) - 1):\n",
    "            input_size = layer_sizes[i]\n",
    "            curr_size = layer_sizes[i + 1]\n",
    "            if i < final_relu_layer:\n",
    "                layer_list.append(nn.ReLU(inplace=False))\n",
    "            layer_list.append(nn.Linear(input_size, curr_size))\n",
    "        self.net = nn.Sequential(*layer_list)\n",
    "        self.last_linear = self.net[-1]\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FHWVLrZGAPS0"
   },
   "source": [
    "## Initialize models, optimizers and image transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hO4ynXflAQ7t"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set trunk model and replace the softmax layer with an identity function\n",
    "trunk = torchvision.models.resnet50(pretrained=True)\n",
    "trunk_output_size = trunk.fc.in_features\n",
    "trunk.fc = common_functions.Identity()\n",
    "trunk = torch.nn.DataParallel(trunk.to(device))\n",
    "\n",
    "# Set embedder model. This takes in the output of the trunk and outputs 32 dimensional embeddings\n",
    "embedder = torch.nn.DataParallel(MLP([trunk_output_size, 32]).to(device))\n",
    "\n",
    "# Set optimizers\n",
    "trunk_optimizer = torch.optim.Adam(trunk.parameters(), lr=0.00001, weight_decay=0.0001)\n",
    "embedder_optimizer = torch.optim.Adam(embedder.parameters(), lr=0.0001, weight_decay=0.0001)\n",
    "\n",
    "# Set the image transforms\n",
    "train_transform = transforms.Compose([transforms.Resize(32),\n",
    "                                      transforms.RandomResizedCrop(scale=(0.16, 1), ratio=(0.75, 1.33), size=32),\n",
    "                                      transforms.RandomHorizontalFlip(0.5),                    \n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "                                      ])\n",
    "\n",
    "val_transform = transforms.Compose([transforms.Resize(32),\n",
    "                                    transforms.CenterCrop(32),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "                                    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Hs8LB8_BjIc"
   },
   "source": [
    "## Create the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kj6qMKoJBiWs"
   },
   "outputs": [],
   "source": [
    "class OnlineProducts_datasets_in_CIFAR(Dataset):\n",
    "  def __init__(self, root, train = True, transform = None):\n",
    "    \"\"\"\n",
    "    Dataset Init-Function.\n",
    "    Args:\n",
    "        root: the root of the dataset.\n",
    "        train: declear that the dataset is training or testing.\n",
    "        transform: the image transform mode you have to set before.\n",
    "    Returns:\n",
    "        Nothing!\n",
    "    \"\"\"\n",
    "    super(OnlineProducts_datasets_in_CIFAR, self).__init__()\n",
    "    self.train = train\n",
    "    self.transform = transform\n",
    "\n",
    "    # if training, load the training annotation file, else load the testing one.\n",
    "    # the .json file stores the info of annotation in dict shape: \n",
    "    #   {'image': filenames, 'label': annotations} where filenames and annotations are arrays.\n",
    "    if self.train:\n",
    "      file_annotation = root + '/annotations/OnlineProducts_train_new.json'\n",
    "    else:\n",
    "      file_annotation = root + '/annotations/OnlineProducts_test_new.json'\n",
    "    self.img_folder = root + '/images/'\n",
    "\n",
    "    # read the file and check if the length of filenames and annotations are same.\n",
    "    fp = open(file_annotation,'r')\n",
    "    data_dict = json.load(fp)\n",
    "    assert len(data_dict['image']) == len(data_dict['label'])\n",
    "    num_data = len(data_dict['image'])\n",
    "    fp.close()\n",
    "\n",
    "    # put the filenames into self.datanames, their annotations into self.targets.\n",
    "    self.datanames = []\n",
    "    self.targets = []\n",
    "    for i in range(num_data):\n",
    "      self.datanames.append(data_dict['image'][i])\n",
    "      self.targets.append(data_dict['label'][i])\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    \"\"\"\n",
    "    Dataset Getitem-Function.\n",
    "    Returns:\n",
    "        img: the data image.\n",
    "        target: the label num of the data. \n",
    "    \"\"\"\n",
    "    img_path = self.img_folder + self.datanames[index]\n",
    "    target = self.targets[index]\n",
    "    # img = plt.imread(img_path)\n",
    "    img = Image.open(img_path)\n",
    "    img = img.convert(\"RGB\")\n",
    "    \n",
    "    if self.transform is not None:\n",
    "      img = self.transform(img)\n",
    "    # img = img.reshape((3, 32, 32))\n",
    "    \n",
    "    # target = np.argmax(target, axis = 0)\n",
    "\n",
    "    return img, target\n",
    "\n",
    "  def __len__(self):\n",
    "        return len(self.datanames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZITsW51zCnhD"
   },
   "outputs": [],
   "source": [
    "%cd\n",
    "my_root = 'metric-learning/SOP_dataset'\n",
    "\n",
    "# Create the original datasets\n",
    "train_dataset = OnlineProducts_datasets_in_CIFAR(root = my_root, train = True, transform = train_transform)\n",
    "val_dataset = OnlineProducts_datasets_in_CIFAR(root = my_root, train = False, transform = val_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5DmWx-XfDmpx"
   },
   "source": [
    "## Create the loss, miner, sampler, and package them into dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ELJGcY-IYGg"
   },
   "outputs": [],
   "source": [
    "# Set the loss function\n",
    "loss = losses.LiftedStructureLoss(neg_margin=1, pos_margin=0)\n",
    "\n",
    "# Set the mining function\n",
    "miner = miners.MultiSimilarityMiner(epsilon=0.1)\n",
    "\n",
    "# Set the dataloader sampler\n",
    "sampler = samplers.MPerClassSampler(train_dataset.targets, m=4, length_before_new_iter=len(train_dataset))\n",
    "\n",
    "# Set other training parameters\n",
    "batch_size = 32\n",
    "num_epochs = 300\n",
    "patience_epochs = None\n",
    "\n",
    "# Package the above stuff into dictionaries.\n",
    "models = {\"trunk\": trunk, \"embedder\": embedder}\n",
    "optimizers = {\"trunk_optimizer\": trunk_optimizer, \"embedder_optimizer\": embedder_optimizer}\n",
    "loss_funcs = {\"metric_loss\": loss}\n",
    "mining_funcs = {\"tuple_miner\": miner}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WNmycNWAIa2J"
   },
   "outputs": [],
   "source": [
    "# Remove logs if you want to train with new parameters\n",
    "!rm -rf example_logs/ example_saved_models/ example_tensorboard/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q18PGmKqIdpb"
   },
   "source": [
    "## Create the training and testing hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DPQDEkxnDoPL"
   },
   "outputs": [],
   "source": [
    "record_keeper, _, _ = logging_presets.get_record_keeper(\"example_logs\", \"example_tensorboard\")\n",
    "hooks = logging_presets.get_hook_container(record_keeper)\n",
    "dataset_dict = {\"val\": val_dataset}\n",
    "model_folder = \"example_saved_models\"\n",
    "\n",
    "def visualizer_hook(umapper, umap_embeddings, labels, split_name, keyname, *args):\n",
    "    logging.info(\"UMAP plot for the {} split and label set {}\".format(split_name, keyname))\n",
    "    label_set = np.unique(labels)\n",
    "    num_classes = len(label_set)\n",
    "    fig = plt.figure(figsize=(20,15))\n",
    "    plt.gca().set_prop_cycle(cycler(\"color\", [plt.cm.nipy_spectral(i) for i in np.linspace(0, 0.9, num_classes)]))\n",
    "    for i in range(num_classes):\n",
    "        idx = labels == label_set[i]\n",
    "        plt.plot(umap_embeddings[idx, 0], umap_embeddings[idx, 1], \".\", markersize=1)   \n",
    "    plt.show()\n",
    "\n",
    "# Create the tester\n",
    "tester = testers.GlobalEmbeddingSpaceTester(end_of_testing_hook = hooks.end_of_testing_hook, \n",
    "                                            visualizer = umap.UMAP(), \n",
    "                                            visualizer_hook = visualizer_hook,\n",
    "                                            dataloader_num_workers = 32,\n",
    "                                            accuracy_calculator=AccuracyCalculator(k=600))\n",
    "\n",
    "end_of_epoch_hook = hooks.end_of_epoch_hook(tester, \n",
    "                                            dataset_dict, \n",
    "                                            model_folder, \n",
    "                                            test_interval = 1,\n",
    "                                            patience = patience_epochs\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rhxQeCjtEHQp"
   },
   "source": [
    "## Create the trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DPF2vClVDzJW"
   },
   "outputs": [],
   "source": [
    "trainer = trainers.MetricLossOnly(models,\n",
    "                                optimizers,\n",
    "                                batch_size,\n",
    "                                loss_funcs,\n",
    "                                mining_funcs,\n",
    "                                train_dataset,\n",
    "                                sampler=sampler,\n",
    "                                dataloader_num_workers = 32,\n",
    "                                end_of_iteration_hook = hooks.end_of_iteration_hook,\n",
    "                                end_of_epoch_hook = end_of_epoch_hook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Drk1jijdIhRB"
   },
   "source": [
    "## Start Tensorboard\n",
    "(Turn off adblock and other shields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_-_SnAF6Ijeh"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir example_tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v-ZGvPBfIrJ2"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NmyOrB0nIo6K"
   },
   "outputs": [],
   "source": [
    "trainer.train(num_epochs=num_epochs)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
